{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialise Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_params(dims):\n",
    "    \"\"\"\n",
    "    ## Generates units in each layer of the network ##\n",
    "    Inputs: number of units in each layer dims = [n0, n1, n2, ..., nL]\n",
    "    output: W = {\"W1\": W1, ..., \"WL\": WL}, b = {\"b1\": b1, ..., \"bL\": bL}\n",
    "    \"\"\"\n",
    "    # Number of layers\n",
    "    L = len(dims) - 1\n",
    "    \n",
    "    # Dictionary of parameters\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(L):\n",
    "        W[\"W\"+str(l+1)] = np.random.randn(dims[l+1], dims[l])\n",
    "        b[\"b\"+str(l+1)] = np.zeros((dims[l+1], 1))\n",
    "    \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "## Test initialise_params() ##\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Layer 1:\n",
      "----------\n",
      "\n",
      "W1 = [[-0.3035558  -0.27386325]\n",
      " [ 0.02504767 -2.42048771]\n",
      " [-1.06034014  0.90046174]\n",
      " [ 0.84970209 -0.70458156]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Layer 2:\n",
      "----------\n",
      "\n",
      "W2 = [[ 0.58560923 -1.06727298 -0.33213454  1.31991766]\n",
      " [ 0.88380192  0.04855433  0.08540305  0.11245358]\n",
      " [-0.87605494  1.71359624 -1.17368316  0.38334488]\n",
      " [ 0.62631414 -0.12176295 -1.68946266  0.62579032]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Layer 3:\n",
      "----------\n",
      "\n",
      "W3 = [[-2.87899745 -2.09551492 -0.24829506 -0.15788123]\n",
      " [ 0.35145937  1.5796131  -0.78909547 -0.87589481]]\n",
      "b3 = [[0.]\n",
      " [0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test initialise_params()\n",
    "dims = [2, 4, 4, 2]\n",
    "W, b = initialise_params(dims)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"## Test initialise_params() ##\")\n",
    "print(\"------------------------------\\n\\n\")\n",
    "\n",
    "for i in range(1,len(dims)):\n",
    "    print(\"Layer {}:\".format(i))\n",
    "    print(\"----------\\n\")\n",
    "    print(\"W\"+str(i)+\" = {}\".format(W[\"W\"+str(i)]))\n",
    "    print(\"b\"+str(i)+\" = {}\\n\".format(b[\"b\"+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Linear Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_linear(A_prev, W, b):\n",
    "    \"\"\"\n",
    "    ## Calculate linear equation for forward pass ##\n",
    "    Inputs: A = previous layer activation, W = current weights, b = current biases\n",
    "    Output: Z = Wâ€¢A + b\n",
    "    \"\"\"\n",
    "    \n",
    "    # Linear Equation\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "## Test forward_linear() ##\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Inputs: \n",
      "----------\n",
      "x =  [[2]\n",
      " [5]]\n",
      "\n",
      "W1 =  [[-0.72148419 -0.06346357]\n",
      " [ 0.43440561  0.58890866]\n",
      " [ 0.07431876  0.23153176]\n",
      " [-0.02325687  1.16768063]]\n",
      "\n",
      "b1 =  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Output: \n",
      "----------\n",
      "Z1 =  [[-1.76028624]\n",
      " [ 3.81335449]\n",
      " [ 1.30629634]\n",
      " [ 5.79188939]]\n"
     ]
    }
   ],
   "source": [
    "# Test forward_linear()\n",
    "x = np.array([[2], [5]])\n",
    "W1 = units[\"W1\"]\n",
    "b1 = units[\"b1\"]\n",
    "\n",
    "Z1 = forward_linear(x, W1, b1)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"## Test forward_linear() ##\")\n",
    "print(\"------------------------------\\n\")\n",
    "\n",
    "print(\"\\nInputs: \\n----------\")\n",
    "print(\"x = \", x)\n",
    "print(\"\\nW1 = \", W1)\n",
    "print(\"\\nb1 = \", b1)\n",
    "\n",
    "print(\"\\nOutput: \\n----------\")\n",
    "print(\"Z1 = \", Z1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Activation Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Activation Functions #\n",
    "########################\n",
    "    \n",
    "\n",
    "# Sigmodal Activation\n",
    "def Sigmoid(Z):\n",
    "    return 1/(1 + np.exp(-Z))\n",
    "\n",
    "# Swish Activation\n",
    "def Swish(Z):\n",
    "    return Z/(1 + np.exp(-Z))\n",
    "\n",
    "# Hyperbolic Tangent\n",
    "def Tanh(Z):\n",
    "    return np.tanh(Z)\n",
    "\n",
    "# Rectified Linear Unit\n",
    "def ReLU(Z):\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "# Leaky Rectified Linear Unit\n",
    "def L_ReLU(Z):\n",
    "    return np.maximum(0.01*Z, Z)\n",
    "\n",
    "# # Parametric Rectified Linear Unit\n",
    "# def P_ReLU(Z):\n",
    "#     return np.maximum(0.05*Z, Z)\n",
    "\n",
    "\n",
    "############################\n",
    "# Forward pass calculation #\n",
    "############################\n",
    "\n",
    "def forward_activation(Z, g):\n",
    "    \"\"\" \n",
    "    ## Applies specified activation function to Z ##\n",
    "    Inputs: Z = linear forward pass, g = activation function\n",
    "    Output: A = g(z) \n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary of activations functions\n",
    "    activations = {\n",
    "        'sigmoid': Sigmoid,\n",
    "        'swish'  : Swish,\n",
    "        'tanh'   : Tanh,\n",
    "        'relu'   : ReLU,\n",
    "        'l_relu' : L_ReLU\n",
    "    }\n",
    "\n",
    "    # Call activation on Z\n",
    "    try:\n",
    "        A = activations[g](Z)\n",
    "        return A\n",
    "    except:\n",
    "        display(print(\"\\n----------------\\nInvalid function\\n----------------\\n\"))\n",
    "        display(print(g))\n",
    "        display(print(\"----------------\\nValid activations:\\n----------------\"))\n",
    "        for key in activations.keys():\n",
    "            display(print(key))\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "## Test forward_activation() ##\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Inputs: \n",
      "----------\n",
      "Z1 =  [[-1.76028624]\n",
      " [ 3.81335449]\n",
      " [ 1.30629634]\n",
      " [ 5.79188939]]\n",
      "\n",
      "g =  relu\n",
      "\n",
      "Output: \n",
      "----------\n",
      "A =  [[0.        ]\n",
      " [3.81335449]\n",
      " [1.30629634]\n",
      " [5.79188939]]\n"
     ]
    }
   ],
   "source": [
    "# Test forward_activation()\n",
    "Z1 = Z1\n",
    "g = \"relu\"\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"## Test forward_activation() ##\")\n",
    "print(\"------------------------------\\n\")\n",
    "\n",
    "print(\"\\nInputs: \\n----------\")\n",
    "print(\"Z1 = \", Z1)\n",
    "print(\"\\ng = \", g)\n",
    "\n",
    "print(\"\\nOutput: \\n----------\")\n",
    "A1 = forward_activation(Z1, g)\n",
    "print(\"A = \", A1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foward_propagation(X, W, b, g):\n",
    "    \"\"\"\n",
    "    ## Completes a full forward pass through Network ##\n",
    "    Inputs: X = Full Feature Set, W = Weights in Network, \n",
    "            b = Biases in Network, g = All Activation Functions\n",
    "    Output: A, Z\n",
    "    \"\"\"\n",
    "    assert(len(W) == len(b))\n",
    "    assert(len(b) == len(g))\n",
    "    assert(len(g) == len(W))\n",
    "    \n",
    "    L = len(W)\n",
    "    A_prev = X\n",
    "    A = {}\n",
    "    Z = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Parameters\n",
    "        bl = b[\"b\"+str(l+1)]\n",
    "        Wl = W[\"W\"+str(l+1)]\n",
    "        \n",
    "        # Current activation \n",
    "        gl = g[\"g\"+str(l+1)]\n",
    "        \n",
    "        # Forward Linear Pass\n",
    "        Zl = forward_linear(A_prev, Wl, bl)\n",
    "        Al = forward_activation(Zl, gl)\n",
    "        \n",
    "        # Chase Values\n",
    "        A[\"A\"+str(l+1)] = Al\n",
    "        Z[\"Z\"+str(l+1)] = Zl\n",
    "        \n",
    "        A_prev = Al   \n",
    "    \n",
    "    return A, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "## Test forward_activation() ##\n",
      "------------------------------\n",
      "\n",
      "\n",
      "N =  [2, 4, 4, 2, 1]\n",
      "-------------------\n",
      "-------------------\n",
      "\n",
      "\n",
      "Layer 1:\n",
      "----------\n",
      "\n",
      "W1 = [[-1.4457343   1.03734989]\n",
      " [ 0.76852187 -1.53801337]\n",
      " [ 0.81016917 -0.78179952]\n",
      " [ 1.26777548  0.24812484]]\n",
      "b1 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Z1 = [[ 2.29528083]\n",
      " [-6.15302312]\n",
      " [-2.28865924]\n",
      " [ 3.77617513]]\n",
      "A1 = [[2.29528083]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [3.77617513]]\n",
      "\n",
      "\n",
      "Layer 2:\n",
      "----------\n",
      "\n",
      "W2 = [[ 1.01882147  0.86149989  0.39889563 -0.10066499]\n",
      " [-1.44505897 -0.51109455 -1.50177042  0.08028097]\n",
      " [ 0.67315815 -1.22538675 -0.9784412  -0.28615619]\n",
      " [ 0.42723869  0.43352469 -0.66567287 -0.6446957 ]]\n",
      "b2 = [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "Z2 = [[ 1.95835274]\n",
      " [-3.01366116]\n",
      " [ 0.46451112]\n",
      " [-1.45385112]]\n",
      "A2 = [[1.95835274]\n",
      " [0.        ]\n",
      " [0.46451112]\n",
      " [0.        ]]\n",
      "\n",
      "\n",
      "Layer 3:\n",
      "----------\n",
      "\n",
      "W3 = [[-1.6408348  -1.66480963 -1.21713812 -1.37673776]\n",
      " [-1.42444564 -0.08732428  0.53161913  0.28062724]]\n",
      "b3 = [[0.]\n",
      " [0.]]\n",
      "\n",
      "Z3 = [[-3.77870752]\n",
      " [-2.54262403]]\n",
      "A3 = [[0.]\n",
      " [0.]]\n",
      "\n",
      "\n",
      "Layer 4:\n",
      "----------\n",
      "\n",
      "W4 = [[0.38106521 1.59654885]]\n",
      "b4 = [[0.]]\n",
      "\n",
      "Z4 = [[0.]]\n",
      "A4 = [[0.5]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test forward_propagation()\n",
    "\n",
    "## Specify inputs\n",
    "X = x\n",
    "dims = [X.shape[0], 4, 4, 2, 1]\n",
    "g = {\n",
    "    \"g1\": 'relu',\n",
    "    \"g2\": 'relu',\n",
    "    \"g3\": 'relu',\n",
    "    \"g4\": 'sigmoid'\n",
    "}\n",
    "\n",
    "## Run initialise_params()\n",
    "W, b = initialise_params(dims)\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"## Test forward_activation() ##\")\n",
    "print(\"------------------------------\\n\\n\")\n",
    "\n",
    "print(\"N = \", dims)\n",
    "print(\"-------------------\\n-------------------\\n\\n\")\n",
    "\n",
    "## Run foward_propagation()\n",
    "A, Z = foward_propagation(X, W, b, g)\n",
    "\n",
    "for i in range(1,len(dims)):\n",
    "    print(\"Layer {}:\".format(i))\n",
    "    print(\"----------\\n\")\n",
    "    print(\"W\"+str(i)+\" = {}\".format(W[\"W\"+str(i)]))\n",
    "    print(\"b\"+str(i)+\" = {}\\n\".format(b[\"b\"+str(i)]))\n",
    "    print(\"Z\"+str(i)+\" = {}\".format(Z[\"Z\"+str(i)]))\n",
    "    print(\"A\"+str(i)+\" = {}\\n\\n\".format(A[\"A\"+str(i)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward Linear Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backwards Linear Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Network Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it all together"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
